{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "\n",
    "## General Form\n",
    "\n",
    "$$\n",
    "h(x) = \\sum_{i=0}^{d} \\theta_i x_i = \\theta^{T}x\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$\\theta$ is the parameters\n",
    "\n",
    "$x$ is the variable\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2} \\sum_{i=1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)})^{2}\n",
    "$$\n",
    "\n",
    "Regresssion with this kind of loss function is called **ordinary least squares**\n",
    "\n",
    "## LMS (Least Mean Squared) Algorithm\n",
    "1. We want to choose $\\theta$ to minimize $J(\\theta)$\n",
    "2. to do so, we start with initial guess\n",
    "3. repeatedly update $\\theta$ to make $J(\\theta)$ smaller\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j - \\alpha \\frac{\\partial}{\\partial\\theta_j}J(\\theta)\n",
    "$$\n",
    "where $\\alpha$ is the learning rate\n",
    "\n",
    "since the derivatives $\\frac{\\partial}{\\partial\\theta_j} J(\\theta)$  is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial\\theta_j} J(\\theta) = (h_\\theta(x) - y)x_j\n",
    "$$\n",
    "\n",
    "then we will get the update rule for $\\theta_j$\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha(y^{(i)} - h_\\theta(x^{(i)}))x^{(i)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_x(theta, x):\n",
    "    \"\"\"\n",
    "    the dot product between weight & x\n",
    "    \"\"\"\n",
    "    return theta @ x\n",
    "\n",
    "def update_theta(theta_j, y, h_x, x, alpha=0.01):\n",
    "    \"\"\"\n",
    "    produces new theta\n",
    "    \"\"\"\n",
    "    return theta_j + alpha * ((y - h_x) @ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "y = np.array([2,4,6])\n",
    "theta = np.array([1,1,1])\n",
    "\n",
    "def learn(theta, x, y, max_iter=1000):\n",
    "    \"\"\"\n",
    "    learn with gradient descent\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    stop = False\n",
    "    h_x1 = h_x(theta, x)\n",
    "    while not stop or i == max_iter:\n",
    "\n",
    "        theta_new = update_theta(theta[j], y, h_x1, x)\n",
    "        h_x1 = h_x(theta, x)\n",
    "\n",
    "        if np.all(np.isclose(theta, theta_new)):\n",
    "            stop = True\n",
    "        theta = theta_new\n",
    "        i += 1\n",
    "    return theta\n",
    "\n",
    "def rmse(y_true, y_predicted):\n",
    "    return np.mean(np.sqrt(np.power(y_predicted - y_true, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial prediction: [6 6 6], rmse: 2.0\n",
      "y: [2 4 6]\n",
      "current_prediction: [4.6662996 4.6662996 4.6662996], rmse: 1.5554332009037826\n"
     ]
    }
   ],
   "source": [
    "pred = h_x(theta, x)\n",
    "print('initial prediction: {}, rmse: {}'.format(pred, rmse(y, pred)))\n",
    "print('y: {}'.format(y))\n",
    "new_theta = learn(theta, x, y)\n",
    "pred = h_x(new_theta, x)\n",
    "print('current_prediction: {}, rmse: {}'.format(pred, rmse(y, pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this algorithm is called **stochastic gradient descent** or **incremental gradient descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. Stanford CS229 Lecture Notes.\n",
    "2. http://tutorial.math.lamar.edu/pdf/calculus_cheat_sheet_derivatives.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
